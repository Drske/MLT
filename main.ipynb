{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.collectors import DataCollector\n",
    "\n",
    "COLLECTOR_KWARGS = {'metric': 'minkowski', 'p': 1}\n",
    "COLLECTOR = DataCollector(metric_kwargs=COLLECTOR_KWARGS)\n",
    "\n",
    "EXPERIMENT='Minkowski/shareY'\n",
    "EXPERIMENT_2='Minkowski/share0'\n",
    "\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "# and https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#finetuning-the-convnet\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def train(model, loaders, criterion, optimizer, scheduler, num_epochs=5, device=torch.device('cpu')):\n",
    "    model.to(device)\n",
    "    \n",
    "    losses = {}\n",
    "    losses['train'], losses['valid'] = [], []\n",
    "    accs = {}\n",
    "    accs['train'], accs['valid'] = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        COLLECTOR.current_epoch = epoch\n",
    "\n",
    "        train_loss, train_acc = one_epoch('train', model, loaders['train'], criterion, scheduler, optimizer, epoch, device)\n",
    "        valid_loss, valid_acc = one_epoch('valid', model, loaders['valid'], criterion, scheduler, optimizer, epoch, device)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc}\")\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {valid_loss:.4f}, Accuracy: {valid_acc}\")\n",
    "        \n",
    "        losses['train'].append(train_loss)\n",
    "        losses['valid'].append(valid_loss)\n",
    "        accs['train'].append(train_acc)\n",
    "        accs['valid'].append(valid_acc)\n",
    "        \n",
    "    return losses, accs\n",
    "\n",
    "def one_epoch(phase, model, loader, criterion, scheduler, optimizer, epoch_idx, device):\n",
    "    if phase == 'train':\n",
    "        model.train()\n",
    "    elif phase == 'valid':\n",
    "        model.eval()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Phase {phase} is not a proper learning phase (use 'train' or 'valid')!\")\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    dataset_size = 0\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(tqdm(loader)):\n",
    "        COLLECTOR.current_batch = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(predictions == labels.data).cpu().numpy()\n",
    "        dataset_size += inputs.size(0)\n",
    "\n",
    "        if phase == 'train' and scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_corrects / dataset_size\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.blocks import BasicBlock, Bottleneck, PlainBasicBlock, PlainBottleneck\n",
    "from src.modules.models import ResNet\n",
    "\n",
    "\n",
    "def resnet(version, in_channels, num_classes, plain=False):\n",
    "    match version:\n",
    "        case 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "            block = BasicBlock if not plain else PlainBasicBlock\n",
    "        case 26:\n",
    "            layers = [2, 2, 2, 2]\n",
    "            block = Bottleneck if not plain else PlainBottleneck\n",
    "        case 34:\n",
    "            layers = [3, 4, 6, 3]\n",
    "            block = BasicBlock if not plain else PlainBasicBlock\n",
    "        case 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "            block = Bottleneck if not plain else PlainBottleneck\n",
    "        case 68:\n",
    "            layers = [3, 4, 23, 3]\n",
    "            block = BasicBlock if not plain else PlainBasicBlock\n",
    "        case 101:\n",
    "            layers = [3, 4, 23, 3]\n",
    "            block = Bottleneck if not plain else PlainBottleneck        \n",
    "        case _:\n",
    "            raise ValueError(f'Version {version} is not a valid ResNet size.')\n",
    "                \n",
    "    model = ResNet(block=block, in_channels=in_channels, layers=layers, num_classes=num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colorbar as colorbar\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_differences(fig, axes, plain: bool, model: ResNet):\n",
    "    title1, title2 = \"Init differences\", \"Next differences\"\n",
    "    if plain:\n",
    "        title1 += \" [Plain]\"\n",
    "        title2 += \" [Plain]\"\n",
    "        column = 0\n",
    "    else:\n",
    "        column = 1\n",
    "        \n",
    "    ax = axes[0][column]\n",
    "    ax.set_title(title1)\n",
    "    for depth, differences in COLLECTOR.init_differences.items():\n",
    "        ax.plot(differences, label=f\"depth = {depth}\", color=plt.cm.coolwarm((depth-1) / model.max_depth))\n",
    "    ax.set_xlabel('Batch number')\n",
    "    ax.set_ylabel('Distance to initial state')\n",
    "        \n",
    "    ax = axes[1][column]\n",
    "    ax.set_title(title2)\n",
    "    for depth, differences in COLLECTOR.next_differences.items():\n",
    "        ax.plot(differences, label=f\"depth = {depth}\", color=plt.cm.coolwarm((depth-1) / model.max_depth))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Batch number')\n",
    "    ax.set_ylabel('Distance to previous state')\n",
    "    \n",
    "    if plain:\n",
    "        for row in [0, 1]:\n",
    "            cbar_ax = fig.add_axes([0.95, axes[row][0].get_position().y0, 0.02, axes[0][0].get_position().height])  # [left, bottom, width, height]\n",
    "            cbar = colorbar.ColorbarBase(cbar_ax, cmap=plt.cm.coolwarm, orientation='vertical')\n",
    "            cbar.set_ticks((np.linspace(1, model.max_depth, model.max_depth) - 1) / (model.max_depth - 1))\n",
    "            cbar.set_ticklabels(np.linspace(1, model.max_depth, model.max_depth))\n",
    "            cbar.set_label('Depth')\n",
    "\n",
    "def plot_metrics(fig, axes, plain: bool, losses: dict, accuracies: dict):\n",
    "    title1, title2 = \"Losses\", \"Accuracies\"\n",
    "    if plain:\n",
    "        title1 += \" [Plain]\"\n",
    "        title2 += \" [Plain]\"\n",
    "        column = 0\n",
    "    else:\n",
    "        column = 1\n",
    "        \n",
    "    ax = axes[0][column]\n",
    "    ax.set_title(title1)\n",
    "    ax.plot(range(1, len(losses['train']) + 1), losses['train'], label='Loss [train]')\n",
    "    ax.plot(range(1, len(losses['valid']) + 1), losses['valid'], label='Loss [valid]')\n",
    "    ax.set_xlabel('Epoch number')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    ax = axes[1][column]\n",
    "    ax.set_title(title2)\n",
    "    ax.plot(range(1, len(accuracies['train']) + 1), accuracies['train'], label='Accuracy [train]')\n",
    "    ax.plot(range(1, len(accuracies['valid']) + 1), accuracies['valid'], label='Accuracy [valid]')\n",
    "    ax.set_xlabel('Epoch number')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "def share_y_axis(fig, axes):\n",
    "    for row in range(len(axes)):\n",
    "        miny, maxy = np.inf, 0\n",
    "        for col in [0, 1]:\n",
    "            for line in axes[row][col].lines:\n",
    "                if line.get_ydata().min() < miny:\n",
    "                    miny = line.get_ydata().min()\n",
    "                if line.get_ydata().max() > maxy:\n",
    "                    maxy = line.get_ydata().max()\n",
    "        \n",
    "        miny -= 0.05 * np.abs(maxy - miny)\n",
    "        maxy += 0.05 * np.abs(maxy - miny)\n",
    "        axes[row][0].set_ylim(miny, maxy)\n",
    "        axes[row][1].set_ylim(miny, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.datasets import cifar100, cifar10, fashion_mnist, mnist\n",
    "\n",
    "loaders = {}\n",
    "    \n",
    "for dataset in [cifar10, cifar100, fashion_mnist, mnist]:\n",
    "    train_loader, valid_loader = dataset()\n",
    "    loaders[\"train\"] = train_loader\n",
    "    loaders[\"valid\"] = valid_loader\n",
    "    \n",
    "    if dataset.__name__ in ['cifar100']:\n",
    "        num_classes = 100\n",
    "    else:\n",
    "        num_classes = 10\n",
    "        \n",
    "    if dataset.__name__ in ['cifar10', 'cifar100']:\n",
    "        in_channels = 3\n",
    "    else:\n",
    "        in_channels = 1\n",
    "        \n",
    "    for version in [18, 26, 34, 50, 68, 101]:\n",
    "        fig_diff, axes_diff = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig_diff.suptitle(f\"Dataset: {dataset.__name__}, Model: ResNet-{version}\")\n",
    "        \n",
    "        fig_metric, axes_metric = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig_metric.suptitle(f\"Dataset: {dataset.__name__}, Model: ResNet-{version}\")\n",
    "            \n",
    "        for plain in [True, False]:\n",
    "            \n",
    "            model = resnet(version, in_channels, num_classes, plain)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters())\n",
    "            scheduler = None # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "            device = torch.device(\"mps\")\n",
    "            \n",
    "            DataCollector.reset_instances()\n",
    "            COLLECTOR = DataCollector(metric_kwargs=COLLECTOR_KWARGS)\n",
    "            \n",
    "            losses, accuracies = train(model, loaders, criterion, optimizer, scheduler, NUM_EPOCHS, device)\n",
    "            \n",
    "            experiment_path = os.path.join(f'experiments/{EXPERIMENT}', dataset.__name__, f\"ResNet-{version} [Plain: {plain}]\")\n",
    "            COLLECTOR.save_state(experiment_path)\n",
    "            \n",
    "            plot_differences(fig_diff, axes_diff, plain, model)            \n",
    "            plot_metrics(fig_metric, axes_metric, plain, losses, accuracies)\n",
    "            \n",
    "        share_y_axis(fig_diff, axes_diff)\n",
    "        fig_diff.savefig(os.path.join(experiment_path, 'differences.png'))\n",
    "        share_y_axis(fig_metric, axes_metric)\n",
    "        fig_metric.savefig(os.path.join(experiment_path, 'metrics.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [cifar10, cifar100, fashion_mnist, mnist]:        \n",
    "    for version in [18, 26, 34, 50, 68, 101]:        \n",
    "        fig_diff, axes_diff = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig_diff.suptitle(f\"Dataset: {dataset.__name__}, Model: ResNet-{version}\")\n",
    "        \n",
    "        fig_metric, axes_metric = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig_metric.suptitle(f\"Dataset: {dataset.__name__}, Model: ResNet-{version}\")\n",
    "            \n",
    "        for plain in [True, False]:            \n",
    "            DataCollector.reset_instances()\n",
    "            COLLECTOR = DataCollector(metric_kwargs=COLLECTOR_KWARGS)\n",
    "            \n",
    "            from_experiment_path = os.path.join(f'experiments/{EXPERIMENT}', dataset.__name__, f\"ResNet-{version} [Plain: {plain}]\")\n",
    "            to_experiment_path = os.path.join(f'experiments/{EXPERIMENT_2}', dataset.__name__, f\"ResNet-{version} [Plain: {plain}]\")\n",
    "            COLLECTOR.load_state(from_experiment_path)\n",
    "            COLLECTOR.save_state(to_experiment_path)\n",
    "            \n",
    "            plot_differences(fig_diff, axes_diff, plain, model)            \n",
    "            plot_metrics(fig_metric, axes_metric, plain, losses, accuracies)\n",
    "            \n",
    "        fig_diff.savefig(os.path.join(to_experiment_path, 'differences.png'))\n",
    "        fig_metric.savefig(os.path.join(to_experiment_path, 'metrics.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "for diff_type, title in zip([\"init\", \"next\"], ['Init differences among datasets', 'Next differences among datasets']):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16,12))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    for idx, dataset in enumerate([cifar10, cifar100, fashion_mnist, mnist]):\n",
    "        array = []\n",
    "            \n",
    "        for version in [18, 26, 34, 50, 68, 101]:\n",
    "            for plain in [True, False]:\n",
    "                DataCollector.reset_instances()\n",
    "                COLLECTOR = DataCollector(metric_kwargs=COLLECTOR_KWARGS)\n",
    "                \n",
    "                experiment_path = os.path.join(f'experiments/{EXPERIMENT}', dataset.__name__, f\"ResNet-{version} [Plain: {plain}]\")\n",
    "                try:\n",
    "                    COLLECTOR.load_state(experiment_path)\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                with open(os.path.join(experiment_path, 'stats.yaml'), 'r') as f:\n",
    "                    stats = yaml.safe_load(f)\n",
    "                    \n",
    "                array.append((version, plain, [], []))\n",
    "                for depth in stats[diff_type].keys():\n",
    "                    array[-1][2].append(depth)\n",
    "                    array[-1][3].append(stats[diff_type][depth]['mean'])\n",
    "        \n",
    "        row, col = idx // 2, idx % 2\n",
    "        axes[row][col].set_title(f\"{dataset.__name__}\")\n",
    "        for version, plain, depths, means in array:\n",
    "            if plain:\n",
    "                axes[row][col].plot(depths, means, label=f\"ResNet-{version}\", linestyle='--', color=plt.cm.prism(version / 101))\n",
    "            else:\n",
    "                axes[row][col].plot(depths, means, label=f\"ResNet-{version}\", color=plt.cm.prism(version / 101))\n",
    "        axes[row][col].set_xlabel('Depth')\n",
    "        axes[row][col].set_ylabel(f'Mean {diff_type} difference')\n",
    "        axes[row][col].legend()\n",
    "        \n",
    "        fig.savefig(os.path.join(f\"experiments/{EXPERIMENT}\"), f\"Gathered {diff_type} differences.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
